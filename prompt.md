üìò AI Project Instructions (prompt.md)

This file contains development rules and best practices for building a data engineering project focused on macroeconomic and financial market data using modern open-source tooling. This file is designed to guide both AI systems (like ChatGPT and Cursor) and human contributors.

‚∏ª

üß† Project Context
	‚Ä¢	Goal: Build a personal data pipeline for macroeconomic data, financial markets (stocks, crypto, commodities, futures, options)
	‚Ä¢	Output Uses: Investment analytics, automated blog generation, internal dashboards
	‚Ä¢	Written In: Python (using Cursor)
	‚Ä¢	Powered By: AI-assisted code generation (e.g., ChatGPT)

‚∏ª

‚úÖ General Development Rules
	1.	Follow Medallion Architecture
	‚Ä¢	Bronze = Raw ingestion
	‚Ä¢	Silver = Cleaned & validated
	‚Ä¢	Gold = Aggregated/analytics-ready
	2.	Default Tech Stack:
	‚Ä¢	Language: Python
	‚Ä¢	Storage: ClickHouse, Apache Iceberg
	‚Ä¢	Infra: Docker, Docker Compose, AWS (S3, EC2, ECR), MinIO (alt to S3), Kubernetes (later phase)
	‚Ä¢	Workflow: Apache Airflow
	‚Ä¢	Web/App: React + TailwindCSS, Streamlit, Gradio (for internal tools)
	3.	Code Practices:
	‚Ä¢	Modular and AI-generatable code
	‚Ä¢	Always include logging, config support (.env/YAML/JSON), data validation
	‚Ä¢	CLI or Notebook interfaces to test pipeline stages
	‚Ä¢	Support local and cloud modes
	4.	All code/tasks must be given in 3 styles:
	‚Ä¢	‚úÖ Best Practice ‚Äî clean, scalable, prod-ready
	‚Ä¢	üõ†Ô∏è Practical ‚Äî simple, fast, local-friendly
	‚Ä¢	üí° Creative ‚Äî experimental or cutting-edge
	5.	Prefer open-source tools unless explicitly asked to use cloud services.

‚∏ª

üß∞ Cursor-Specific Instructions
	6.	Cursor Rules and MCP Config:
	‚Ä¢	When relevant to a task, provide optimized cursor.rules or mcp suggestions
	‚Ä¢	Tailor rules to support smart file routing, formatting, and autocomplete
	‚Ä¢	Assume all code will be written and tested inside Cursor

‚∏ª

üìà Pipeline Rules
	7.	Ingestion Scripts Should:
	‚Ä¢	Separate concerns (download, load, transform)
	‚Ä¢	Include basic schema validation, null/missing detection
	‚Ä¢	Be fully logged and config-driven
	8.	ClickHouse Usage:
	‚Ä¢	Use native formats (Parquet, ORC) for bulk loads
	‚Ä¢	Include table DDL, schema, indexes
	‚Ä¢	Optimize inserts for performance (batching, partitioning)

‚∏ª

üåê Web & App Phase (Later)
	9.	Frontend Tools:
	‚Ä¢	React or Next.js + TailwindCSS
	‚Ä¢	Use Streamlit/Gradio for internal dashboards or quick POCs
	10.	Blog Generation:

	‚Ä¢	Markdown or static site generation with templated insights
	‚Ä¢	Possibly integrate with Notion, GitHub Pages, or a JAMstack CMS

‚∏ª

‚ú® Final Guidelines
	‚Ä¢	Keep everything modular and AI-friendly
	‚Ä¢	Use clean naming conventions and docstrings
	‚Ä¢	Ask for clarification before making assumptions
	‚Ä¢	Include dev vs prod config toggles where needed

‚∏ª

This file can be referenced by any LLM agents, collaborators, or AI-based tooling to align contributions with the project‚Äôs architecture, tech stack, and goals.